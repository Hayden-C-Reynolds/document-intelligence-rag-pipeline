{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# End-to-End Multi-Document RAG System (with OCR + Query Routing)\n",
        "\n",
        "This notebook implements a document Q&A pipeline that can ingest mixed PDFs (digital + scanned),\n",
        "detect and classify multiple logical documents, index them with embeddings, and answer user questions\n",
        "with source attribution (document type + page range) through a Gradio chatbot UI.\n",
        "\n",
        "**Key capabilities**\n",
        "- Multi-document boundary detection + document-type classification\n",
        "- OCR fallback for scanned / image-only pages (Tesseract)\n",
        "- Chunking with overlap (500 words, 100 overlap) + metadata preservation\n",
        "- Dense vector retrieval with query routing by document type (FAISS)\n",
        "- LLM answer generation constrained to retrieved context (Gemini 2.5 Flash-Lite)\n",
        "\n"
      ],
      "metadata": {
        "id": "Oh6V_eigIL1i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üìö Setup\n",
        "Install dependencies for:\n",
        "- UI (Gradio)\n",
        "- PDF parsing + page rendering (PyMuPDF / PyPDF2)\n",
        "- OCR (Tesseract + pytesseract)\n",
        "- Embeddings + vector search (SentenceTransformers + FAISS)\n",
        "- LLM + optional framework utilities (Gemini + LlamaIndex utilities)\n"
      ],
      "metadata": {
        "id": "riBw_f9-IY4T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages\n",
        "!pip install -q gradio\n",
        "!pip install -q gradio_pdf\n",
        "!pip install -q pypdf PyPDF2 pymupdf\n",
        "!pip install -q sentence-transformers transformers\n",
        "!pip install -q faiss-cpu\n",
        "!pip install -q google-generativeai\n",
        "!pip install -q numpy pandas\n",
        "!apt-get -qq install -y tesseract-ocr\n",
        "!pip -q install pytesseract pillow\n",
        "\n",
        "# Install LlamaIndex packages for enhanced document processing\n",
        "!pip install -q llama-index\n",
        "!pip install -q llama-index-readers-file\n",
        "!pip install -q llama-index-embeddings-huggingface\n",
        "!pip install -q llama-index-vector-stores-faiss\n",
        "!pip install -q llama-index-llms-gemini\n"
      ],
      "metadata": {
        "id": "MEXBca59DFk2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üîß Imports & Configuration\n",
        "Load libraries, initialize the LLM client, and configure embedding models used for retrieval.\n"
      ],
      "metadata": {
        "id": "_0qPyDllJbDH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "from gradio_pdf import PDF\n",
        "import fitz  # PyMuPDF\n",
        "from PyPDF2 import PdfReader\n",
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import faiss\n",
        "import google.generativeai as genai\n",
        "from typing import List, Dict, Tuple, Optional\n",
        "from dataclasses import dataclass\n",
        "import json\n",
        "from datetime import datetime\n",
        "import hashlib\n",
        "import os\n",
        "import tempfile\n",
        "import csv\n",
        "from google.colab import userdata\n",
        "\n",
        "\n",
        "\n",
        "# LlamaIndex imports for enhanced document processing\n",
        "from llama_index.core import Document, VectorStoreIndex, StorageContext\n",
        "from llama_index.core.schema import TextNode\n",
        "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
        "from llama_index.core.node_parser import SentenceSplitter\n",
        "from llama_index.core.vector_stores import MetadataFilters, MetadataFilter, FilterOperator\n",
        "\n",
        "\n",
        "# --- LLM Configuration (Gemini) ---\n",
        "# Reads API key from Colab Secrets. Keeps keys out of the notebook and version control.\n",
        "GEMINI_API_KEY = userdata.get(\"GEMINI_API_KEY\")\n",
        "if not GEMINI_API_KEY:\n",
        "    raise ValueError(\"Missing GEMINI_API_KEY in Colab Secrets.\")\n",
        "genai.configure(api_key=GEMINI_API_KEY)\n",
        "gemini_model = genai.GenerativeModel(\"models/gemini-2.5-flash-lite\")\n",
        "\n",
        "# --- Embeddings ---\n",
        "# Sentence-BERT (all-MiniLM-L6-v2) provides lightweight, fast embeddings for dense retrieval.\n",
        "embed_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "llama_embed_model = HuggingFaceEmbedding(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "\n",
        "\n",
        "def llm_generate(prompt: str) -> str:\n",
        "    \"\"\"\n",
        "    Wrapper around Gemini generation.\n",
        "    - temperature=0 for deterministic outputs during evaluation\n",
        "    - returns plain text only (safe extraction from response candidates)\n",
        "    \"\"\"\n",
        "    response = gemini_model.generate_content(\n",
        "        prompt,\n",
        "        generation_config={\n",
        "            \"temperature\": 0.0,\n",
        "            \"max_output_tokens\": 512,\n",
        "        }\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        parts = []\n",
        "        for cand in getattr(response, \"candidates\", []) or []:\n",
        "            content = getattr(cand, \"content\", None)\n",
        "            if not content:\n",
        "                continue\n",
        "            for part in getattr(content, \"parts\", []) or []:\n",
        "                if hasattr(part, \"text\"):\n",
        "                    parts.append(part.text)\n",
        "\n",
        "        stitched = \"\".join(parts).strip()\n",
        "        if stitched:\n",
        "            return stitched\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    return (getattr(response, \"text\", \"\") or \"\").strip()\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "N_QN4jpxJcGt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üìÑ Data Structures\n",
        "Lightweight dataclasses used to track:\n",
        "- page-level text extraction\n",
        "- logical document boundaries within a PDF\n",
        "- chunk metadata (doc type, page range, retrieval info)\n"
      ],
      "metadata": {
        "id": "J9FtUNVZJjnz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclass\n",
        "class PageInfo:\n",
        "    \"\"\"Stores information about a single page\"\"\"\n",
        "    page_num: int\n",
        "    text: str\n",
        "    doc_type: Optional[str] = None\n",
        "    page_in_doc: int = 0\n",
        "\n",
        "@dataclass\n",
        "class LogicalDocument:\n",
        "    \"\"\"Represents a logical document within a PDF\"\"\"\n",
        "    doc_id: str\n",
        "    doc_type: str\n",
        "    page_start: int\n",
        "    page_end: int\n",
        "    text: str\n",
        "    chunks: List[Dict] = None\n",
        "\n",
        "@dataclass\n",
        "class ChunkMetadata:\n",
        "    \"\"\"Rich metadata for each chunk\"\"\"\n",
        "    chunk_id: str\n",
        "    doc_id: str\n",
        "    doc_type: str\n",
        "    chunk_index: int\n",
        "    page_start: int\n",
        "    page_end: int\n",
        "    text: str\n",
        "    embedding: Optional[np.ndarray] = None"
      ],
      "metadata": {
        "id": "NiN5Ydr1Jpio"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üß† Document Intelligence\n",
        "Detect document boundaries and classify document types so retrieval can be routed to the most\n",
        "relevant subset of chunks (improves precision in multi-document PDFs).\n"
      ],
      "metadata": {
        "id": "rMN46qYfJrz9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def classify_document_type(text: str, max_length: int = 1500) -> str:\n",
        "    \"\"\"\n",
        "    Classify the document type based on its content.\n",
        "    Uses LLM to intelligently identify document category.\n",
        "    \"\"\"\n",
        "    # Truncate text if too long to avoid token limits\n",
        "    text_sample = text[:max_length] if len(text) > max_length else text\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    Analyze this document and classify it into ONE of these categories:\n",
        "    - Resume: CV, professional profile, work history\n",
        "    - Contract: Legal agreement, terms and conditions, service agreement\n",
        "    - Mortgage Contract: Home loan agreement, mortgage terms, property financing\n",
        "    - Invoice: Bill, payment request, financial statement\n",
        "    - Pay Slip: Salary statement, wage slip, earnings statement\n",
        "    - Lender Fee Sheet: Loan fees, lender charges, closing costs\n",
        "    - Land Deed: Property deed, title document, ownership certificate\n",
        "    - Bank Statement: Account statement, transaction history\n",
        "    - Tax Document: W2, 1099, tax return, tax form\n",
        "    - Insurance: Insurance policy, coverage document\n",
        "    - Report: Analysis, research document, findings\n",
        "    - Letter: Correspondence, memo, communication\n",
        "    - Form: Application, questionnaire, data entry form\n",
        "    - ID Document: Driver's license, passport, identification\n",
        "    - Medical: Medical report, prescription, health record\n",
        "    - Other: Doesn't fit other categories\n",
        "\n",
        "    Document sample:\n",
        "    {text_sample}\n",
        "\n",
        "    Respond with ONLY the category name, nothing else.\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        doc_type = llm_generate(prompt).strip()\n",
        "\n",
        "\n",
        "        # Normalize the response\n",
        "        valid_types = [\n",
        "            'Resume', 'Contract', 'Mortgage Contract', 'Invoice', 'Pay Slip',\n",
        "            'Lender Fee Sheet', 'Land Deed', 'Bank Statement', 'Tax Document',\n",
        "            'Insurance', 'Report', 'Letter', 'Form', 'ID Document',\n",
        "            'Medical', 'Other'\n",
        "        ]\n",
        "\n",
        "        # Find best match (case-insensitive)\n",
        "        for valid_type in valid_types:\n",
        "            if doc_type.lower() == valid_type.lower():\n",
        "                return valid_type\n",
        "\n",
        "        return 'Other'\n",
        "    except Exception as e:\n",
        "        print(f\"Classification error: {e}\")\n",
        "        return 'Other'\n",
        "\n",
        "def detect_document_boundary(prev_text: str, curr_text: str,\n",
        "                            current_doc_type: str = None) -> bool:\n",
        "    \"\"\"\n",
        "    Detect if two consecutive pages belong to the same document.\n",
        "    Returns True if they're from the same document.\n",
        "    \"\"\"\n",
        "    # Quick heuristic checks first\n",
        "    if not prev_text or not curr_text:\n",
        "        return False\n",
        "\n",
        "    # Sample the texts for LLM analysis\n",
        "    prev_sample = prev_text[-500:] if len(prev_text) > 500 else prev_text\n",
        "    curr_sample = curr_text[:500] if len(curr_text) > 500 else curr_text\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    Determine if these two pages are from the SAME document.\n",
        "\n",
        "    Current document type: {current_doc_type or 'Unknown'}\n",
        "\n",
        "    End of Previous Page:\n",
        "    ...{prev_sample}\n",
        "\n",
        "    Start of Current Page:\n",
        "    {curr_sample}...\n",
        "\n",
        "    Consider:\n",
        "    - Continuity of content\n",
        "    - Formatting consistency\n",
        "    - Topic coherence\n",
        "    - Page numbers or headers\n",
        "\n",
        "    Answer ONLY 'Yes' if same document or 'No' if different document.\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        return llm_generate(prompt).strip().lower().startswith(\"yes\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Boundary detection error: {e}\")\n",
        "        # Default to keeping pages together if uncertain\n",
        "        return True"
      ],
      "metadata": {
        "id": "TSkSE_xPIZQK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üìë PDF Extraction & Document Segmentation\n",
        "Extract text page-by-page (OCR fallback when needed), then split the PDF into logical documents\n",
        "using boundary detection. Each logical document is labeled with a document type.\n"
      ],
      "metadata": {
        "id": "sz_YivbFJ10K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_and_analyze_pdf(pdf_file) -> Tuple[List[PageInfo], List[LogicalDocument]]:\n",
        "    \"\"\"\n",
        "    Extract text from PDF and perform intelligent document analysis.\n",
        "    Returns both page-level info and logical document groupings.\n",
        "    Supports various file types including scanned PDFs with OCR.\n",
        "    \"\"\"\n",
        "    print(\"üìñ Starting PDF extraction and analysis...\")\n",
        "\n",
        "    # Extract text from each page\n",
        "    if isinstance(pdf_file, dict) and \"content\" in pdf_file:\n",
        "        doc = fitz.open(stream=pdf_file[\"content\"], filetype=\"pdf\")\n",
        "    elif hasattr(pdf_file, \"read\"):\n",
        "        doc = fitz.open(stream=pdf_file.read(), filetype=\"pdf\")\n",
        "    else:\n",
        "        doc = fitz.open(pdf_file)\n",
        "\n",
        "    pages_info = []\n",
        "    for i, page in enumerate(doc):\n",
        "        text = page.get_text()\n",
        "\n",
        "        # OCR fallback: used only when a page has no selectable text (common for scanned PDFs).\n",
        "\n",
        "        if not text.strip():\n",
        "            print(f\"  Page {i}: No text found, attempting OCR...\")\n",
        "            try:\n",
        "                # Convert page to image and perform OCR\n",
        "                pix = page.get_pixmap(matrix=fitz.Matrix(2, 2))  # higher res helps OCR\n",
        "                img_data = pix.tobytes(\"png\")\n",
        "\n",
        "                from PIL import Image\n",
        "                import pytesseract, io\n",
        "\n",
        "                img = Image.open(io.BytesIO(img_data)).convert(\"L\")  # grayscale\n",
        "                text = pytesseract.image_to_string(img, config=\"--oem 3 --psm 6\")\n",
        "\n",
        "                print(f\"  Page {i}: OCR extracted {len(text)} characters\")\n",
        "            except Exception as e:\n",
        "                print(f\"  Page {i}: OCR failed - {e}\")\n",
        "                text = \"\"\n",
        "\n",
        "        pages_info.append(PageInfo(page_num=i, text=text))\n",
        "\n",
        "    doc.close()\n",
        "\n",
        "    if not pages_info:\n",
        "        raise ValueError(\"No text could be extracted from PDF\")\n",
        "\n",
        "    print(f\"‚úÖ Extracted {len(pages_info)} pages\")\n",
        "\n",
        "    # Perform document classification and boundary detection\n",
        "    print(\"üß† Analyzing document structure...\")\n",
        "    logical_docs = []\n",
        "    current_doc_type = None\n",
        "    current_doc_pages = []\n",
        "    doc_counter = 0\n",
        "\n",
        "    for i, page_info in enumerate(pages_info):\n",
        "        if i == 0:\n",
        "            # First page - classify document type\n",
        "            current_doc_type = classify_document_type(page_info.text)\n",
        "            page_info.doc_type = current_doc_type\n",
        "            page_info.page_in_doc = 0\n",
        "            current_doc_pages = [page_info]\n",
        "            print(f\"  Page {i}: New document detected - {current_doc_type}\")\n",
        "        else:\n",
        "            # Check if this page continues the previous document\n",
        "            prev_text = pages_info[i-1].text\n",
        "            is_same = detect_document_boundary(prev_text, page_info.text, current_doc_type)\n",
        "\n",
        "            if is_same:\n",
        "                # Continue current document\n",
        "                page_info.doc_type = current_doc_type\n",
        "                page_info.page_in_doc = len(current_doc_pages)\n",
        "                current_doc_pages.append(page_info)\n",
        "            else:\n",
        "                # New document detected - save previous and start new\n",
        "                logical_doc = LogicalDocument(\n",
        "                    doc_id=f\"doc_{doc_counter}\",\n",
        "                    doc_type=current_doc_type,\n",
        "                    page_start=current_doc_pages[0].page_num,\n",
        "                    page_end=current_doc_pages[-1].page_num,\n",
        "                    text=\"\\n\\n\".join([p.text for p in current_doc_pages])\n",
        "                )\n",
        "                logical_docs.append(logical_doc)\n",
        "                doc_counter += 1\n",
        "\n",
        "                # Start new document\n",
        "                current_doc_type = classify_document_type(page_info.text)\n",
        "                page_info.doc_type = current_doc_type\n",
        "                page_info.page_in_doc = 0\n",
        "                current_doc_pages = [page_info]\n",
        "                print(f\"  Page {i}: New document detected - {current_doc_type}\")\n",
        "\n",
        "    # Don't forget the last document\n",
        "    if current_doc_pages:\n",
        "        logical_doc = LogicalDocument(\n",
        "            doc_id=f\"doc_{doc_counter}\",\n",
        "            doc_type=current_doc_type,\n",
        "            page_start=current_doc_pages[0].page_num,\n",
        "            page_end=current_doc_pages[-1].page_num,\n",
        "            text=\"\\n\\n\".join([p.text for p in current_doc_pages])\n",
        "        )\n",
        "        logical_docs.append(logical_doc)\n",
        "\n",
        "    print(f\"‚úÖ Identified {len(logical_docs)} logical documents\")\n",
        "    for ld in logical_docs:\n",
        "        print(f\"   - {ld.doc_type}: Pages {ld.page_start}-{ld.page_end}\")\n",
        "\n",
        "    return pages_info, logical_docs"
      ],
      "metadata": {
        "id": "PIBKFsndJ5TT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ‚úÇÔ∏è Chunking & Metadata\n",
        "Chunk each logical document into overlapping windows (500 words, 100 overlap) and attach metadata\n",
        "(doc type + page range) so results can be cited in the final answer.\n"
      ],
      "metadata": {
        "id": "LM89pqZjK_mK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def chunk_document_with_metadata(logical_doc: LogicalDocument,\n",
        "                                chunk_size: int = 500,\n",
        "                                overlap: int = 100) -> List[ChunkMetadata]:\n",
        "    \"\"\"\n",
        "    Chunk a logical document while preserving rich metadata.\n",
        "    Uses sliding window with overlap for better context.\n",
        "    \"\"\"\n",
        "    chunks_metadata = []\n",
        "    words = logical_doc.text.split()\n",
        "\n",
        "    if len(words) <= chunk_size:\n",
        "        # Document is small enough to be a single chunk\n",
        "        chunk_meta = ChunkMetadata(\n",
        "            chunk_id=f\"{logical_doc.doc_id}_chunk_0\",\n",
        "            doc_id=logical_doc.doc_id,\n",
        "            doc_type=logical_doc.doc_type,\n",
        "            chunk_index=0,\n",
        "            page_start=logical_doc.page_start,\n",
        "            page_end=logical_doc.page_end,\n",
        "            text=logical_doc.text\n",
        "        )\n",
        "        chunks_metadata.append(chunk_meta)\n",
        "    else:\n",
        "        # Create overlapping chunks\n",
        "        stride = chunk_size - overlap\n",
        "        for i, start_idx in enumerate(range(0, len(words), stride)):\n",
        "            end_idx = min(start_idx + chunk_size, len(words))\n",
        "            chunk_text = ' '.join(words[start_idx:end_idx])\n",
        "\n",
        "            # Calculate which pages this chunk spans\n",
        "            # NOTE: Page span estimation is approximate.\n",
        "            # A production version would track token-to-page mapping precisely.\n",
        "            chunk_position = start_idx / len(words)\n",
        "            page_range = logical_doc.page_end - logical_doc.page_start\n",
        "            relative_page = int(chunk_position * page_range)\n",
        "            chunk_page_start = logical_doc.page_start + relative_page\n",
        "            chunk_page_end = min(chunk_page_start + 1, logical_doc.page_end)\n",
        "\n",
        "            chunk_meta = ChunkMetadata(\n",
        "                chunk_id=f\"{logical_doc.doc_id}_chunk_{i}\",\n",
        "                doc_id=logical_doc.doc_id,\n",
        "                doc_type=logical_doc.doc_type,\n",
        "                chunk_index=i,\n",
        "                page_start=chunk_page_start,\n",
        "                page_end=chunk_page_end,\n",
        "                text=chunk_text\n",
        "            )\n",
        "            chunks_metadata.append(chunk_meta)\n",
        "\n",
        "            if end_idx >= len(words):\n",
        "                break\n",
        "\n",
        "    return chunks_metadata\n",
        "\n",
        "def chunk_with_llama_index(logical_doc: LogicalDocument,\n",
        "                           chunk_size: int = 500,\n",
        "                           chunk_overlap: int = 100) -> List[Document]:\n",
        "    \"\"\"\n",
        "    Alternative: Use LlamaIndex's advanced chunking with metadata.\n",
        "    \"\"\"\n",
        "    # Create LlamaIndex document with metadata\n",
        "    doc = Document(\n",
        "        text=logical_doc.text,\n",
        "        metadata={\n",
        "            \"doc_id\": logical_doc.doc_id,\n",
        "            \"doc_type\": logical_doc.doc_type,\n",
        "            \"page_start\": logical_doc.page_start,\n",
        "            \"page_end\": logical_doc.page_end,\n",
        "            \"source\": f\"{logical_doc.doc_type}_document\"\n",
        "        }\n",
        "    )\n",
        "\n",
        "    # Use LlamaIndex's sentence splitter for better chunking\n",
        "    splitter = SentenceSplitter(\n",
        "        chunk_size=chunk_size,\n",
        "        chunk_overlap=chunk_overlap,\n",
        "        paragraph_separator=\"\\n\\n\",\n",
        "        separator=\" \",\n",
        "    )\n",
        "\n",
        "    # Create nodes (chunks) from document\n",
        "    nodes = splitter.get_nodes_from_documents([doc])\n",
        "\n",
        "    # Convert to our ChunkMetadata format for consistency\n",
        "    chunks_metadata = []\n",
        "    for i, node in enumerate(nodes):\n",
        "        chunk_meta = ChunkMetadata(\n",
        "            chunk_id=f\"{logical_doc.doc_id}_chunk_{i}\",\n",
        "            doc_id=logical_doc.doc_id,\n",
        "            doc_type=logical_doc.doc_type,\n",
        "            chunk_index=i,\n",
        "            page_start=node.metadata.get(\"page_start\", logical_doc.page_start),\n",
        "            page_end=node.metadata.get(\"page_end\", logical_doc.page_end),\n",
        "            text=node.text\n",
        "        )\n",
        "        chunks_metadata.append(chunk_meta)\n",
        "\n",
        "    return chunks_metadata\n",
        "\n",
        "def process_all_documents(logical_docs: List[LogicalDocument],\n",
        "                         use_llama_index: bool = False) -> List[ChunkMetadata]:\n",
        "    \"\"\"\n",
        "    Process all logical documents into chunks with metadata.\n",
        "    Can use either custom or LlamaIndex chunking.\n",
        "    \"\"\"\n",
        "    all_chunks = []\n",
        "\n",
        "    for logical_doc in logical_docs:\n",
        "        if use_llama_index:\n",
        "            chunks = chunk_with_llama_index(logical_doc)\n",
        "        else:\n",
        "            chunks = chunk_document_with_metadata(logical_doc)\n",
        "\n",
        "        logical_doc.chunks = chunks  # Store reference\n",
        "        all_chunks.extend(chunks)\n",
        "        print(f\"üìÑ {logical_doc.doc_type}: Created {len(chunks)} chunks\")\n",
        "\n",
        "    return all_chunks"
      ],
      "metadata": {
        "id": "G6jI6IMnLCX1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üéØ Retrieval (Dense Vector Search + Query Routing)\n",
        "We use dense embeddings + FAISS for similarity search. For multi-document PDFs, we route queries to the\n",
        "most likely document type (when confidence is high) to reduce noise and improve precision.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "RESzcztYLEgS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_query_document_type(query: str) -> Tuple[str, float]:\n",
        "    \"\"\"\n",
        "    Predict which document type is most likely to contain the answer.\n",
        "    Returns predicted type and confidence score.\n",
        "    \"\"\"\n",
        "    prompt = f\"\"\"\n",
        "    Analyze this query and predict which document type would most likely contain the answer.\n",
        "\n",
        "    Query: \"{query}\"\n",
        "\n",
        "    Choose the MOST LIKELY type from:\n",
        "    - Resume: Career, experience, education, skills, employment history\n",
        "    - Contract: Terms, agreements, obligations, parties, legal terms\n",
        "    - Mortgage Contract: Home loan, property financing, mortgage terms, interest rates\n",
        "    - Invoice: Payments, amounts due, billing, charges, invoiced items\n",
        "    - Pay Slip: Salary, wages, deductions, earnings, pay period\n",
        "    - Lender Fee Sheet: Loan fees, closing costs, origination fees, lender charges\n",
        "    - Land Deed: Property ownership, deed information, property description, title\n",
        "    - Bank Statement: Account balance, transactions, deposits, withdrawals\n",
        "    - Tax Document: Tax information, W2, 1099, tax returns, tax amounts\n",
        "    - Insurance: Coverage, policy details, premiums, claims\n",
        "    - Report: Analysis, findings, conclusions, research data\n",
        "    - Letter: Communications, requests, notifications, correspondence\n",
        "    - Form: Applications, submitted data, form fields\n",
        "    - ID Document: Personal identification, ID numbers, identity verification\n",
        "    - Medical: Health information, medical conditions, prescriptions\n",
        "    - Other: General or unclear\n",
        "\n",
        "    Respond in JSON format:\n",
        "    {{\"type\": \"DocumentType\", \"confidence\": 0.85}}\n",
        "\n",
        "    Confidence should be between 0.0 and 1.0\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        result = json.loads(llm_generate(prompt).strip())\n",
        "\n",
        "        return result.get(\"type\", \"Other\"), result.get(\"confidence\", 0.5)\n",
        "    except Exception as e:\n",
        "        print(f\"Query routing error: {e}\")\n",
        "        return \"Other\", 0.0\n",
        "\n",
        "class IntelligentRetriever:\n",
        "    \"\"\"\n",
        "    Advanced retrieval system with metadata filtering and query routing.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.index = None\n",
        "        self.chunks_metadata = []\n",
        "        self.doc_type_indices = {}  # Separate indices per doc type\n",
        "\n",
        "    def build_indices(self, chunks_metadata: List[ChunkMetadata]):\n",
        "        \"\"\"\n",
        "        Build FAISS indices with document type segregation.\n",
        "        \"\"\"\n",
        "        print(\"üî® Building vector indices...\")\n",
        "        self.chunks_metadata = chunks_metadata\n",
        "\n",
        "        # Create embeddings for all chunks\n",
        "        texts = [chunk.text for chunk in chunks_metadata]\n",
        "        embeddings = embed_model.encode(texts, show_progress_bar=True)\n",
        "\n",
        "        # Store embeddings in metadata\n",
        "        for i, chunk in enumerate(chunks_metadata):\n",
        "            chunk.embedding = embeddings[i]\n",
        "\n",
        "        # Build main index\n",
        "        dim = embeddings.shape[1]\n",
        "        self.index = faiss.IndexFlatL2(dim)\n",
        "        self.index.add(embeddings)\n",
        "\n",
        "        # Build separate indices for each document type\n",
        "        doc_types = set(chunk.doc_type for chunk in chunks_metadata)\n",
        "        for doc_type in doc_types:\n",
        "            type_indices = [i for i, chunk in enumerate(chunks_metadata)\n",
        "                          if chunk.doc_type == doc_type]\n",
        "            if type_indices:\n",
        "                type_embeddings = embeddings[type_indices]\n",
        "                type_index = faiss.IndexFlatL2(dim)\n",
        "                type_index.add(type_embeddings)\n",
        "                self.doc_type_indices[doc_type] = {\n",
        "                    'index': type_index,\n",
        "                    'mapping': type_indices  # Maps back to original chunks\n",
        "                }\n",
        "\n",
        "        print(f\"‚úÖ Indexed {len(chunks_metadata)} chunks across {len(doc_types)} document types\")\n",
        "\n",
        "    def retrieve(self, query: str, k: int = 4,\n",
        "                filter_doc_type: Optional[str] = None,\n",
        "                auto_route: bool = True) -> List[Tuple[ChunkMetadata, float]]:\n",
        "        \"\"\"\n",
        "        Retrieve relevant chunks with optional filtering and routing.\n",
        "        Returns chunks with relevance scores.\n",
        "        \"\"\"\n",
        "        query_embedding = embed_model.encode([query])\n",
        "\n",
        "        # Determine which index to search\n",
        "        if filter_doc_type and filter_doc_type in self.doc_type_indices:\n",
        "            # Use filtered index\n",
        "            type_data = self.doc_type_indices[filter_doc_type]\n",
        "            D, I = type_data['index'].search(query_embedding, k)\n",
        "            # Map back to original chunks\n",
        "            chunk_indices = [type_data['mapping'][i] for i in I[0]]\n",
        "            distances = D[0]\n",
        "        elif auto_route:\n",
        "            # Predict best document type\n",
        "            predicted_type, confidence = predict_query_document_type(query)\n",
        "            print(f\"üéØ Query routed to: {predicted_type} (confidence: {confidence:.2f})\")\n",
        "\n",
        "            if confidence > 0.7 and predicted_type in self.doc_type_indices:\n",
        "                # High confidence - use specific index\n",
        "                type_data = self.doc_type_indices[predicted_type]\n",
        "                D, I = type_data['index'].search(query_embedding, k)\n",
        "                chunk_indices = [type_data['mapping'][i] for i in I[0]]\n",
        "                distances = D[0]\n",
        "            else:\n",
        "                # Low confidence - search all\n",
        "                D, I = self.index.search(query_embedding, k)\n",
        "                chunk_indices = I[0]\n",
        "                distances = D[0]\n",
        "        else:\n",
        "            # Search all chunks\n",
        "            D, I = self.index.search(query_embedding, k)\n",
        "            chunk_indices = I[0]\n",
        "            distances = D[0]\n",
        "\n",
        "        # Convert distances to similarity scores (inverse)\n",
        "        max_dist = max(distances) if len(distances) > 0 else 1.0\n",
        "        scores = [(max_dist - d) / max_dist for d in distances]\n",
        "\n",
        "        results = [(self.chunks_metadata[i], scores[idx])\n",
        "                  for idx, i in enumerate(chunk_indices)]\n",
        "\n",
        "        return results"
      ],
      "metadata": {
        "id": "Tqd7HSzPLMVJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üí¨ Enhanced Answer Generation with Source\n",
        "Use the retrieved chunks as the only allowed context for the LLM. The response includes:\n",
        "- final answer\n",
        "- document type + page ranges used\n",
        "- simple confidence signal based on retrieval similarity"
      ],
      "metadata": {
        "id": "fT4Dws--LN2F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_answer_with_sources(query: str,\n",
        "                                retrieved_chunks: List[Tuple[ChunkMetadata, float]]) -> Dict:\n",
        "    \"\"\"\n",
        "    Generate answer with detailed source attribution.\n",
        "    \"\"\"\n",
        "    if not retrieved_chunks:\n",
        "        return {\n",
        "            'answer': \"I couldn't find relevant information to answer your question.\",\n",
        "            'sources': [],\n",
        "            'confidence': 0.0\n",
        "        }\n",
        "\n",
        "    # Prepare context from retrieved chunks\n",
        "    context_parts = []\n",
        "    sources = []\n",
        "\n",
        "    for chunk_meta, score in retrieved_chunks:\n",
        "        context_parts.append(f\"[From {chunk_meta.doc_type}, Pages {chunk_meta.page_start}-{chunk_meta.page_end}]\")\n",
        "        context_parts.append(chunk_meta.text)\n",
        "        context_parts.append(\"\")\n",
        "\n",
        "        sources.append({\n",
        "            'doc_type': chunk_meta.doc_type,\n",
        "            'pages': f\"{chunk_meta.page_start}-{chunk_meta.page_end}\",\n",
        "            'relevance': f\"{score:.2%}\",\n",
        "            'preview': chunk_meta.text[:100] + \"...\"\n",
        "        })\n",
        "\n",
        "    context = \"\\n\".join(context_parts)\n",
        "\n",
        "    # Generate answer\n",
        "    prompt = f\"\"\"\n",
        "    You are a helpful AI assistant. Use the provided context to answer the question.\n",
        "    Be specific and cite which document type and pages support your answer.\n",
        "\n",
        "    Context:\n",
        "    {context}\n",
        "\n",
        "    Question: {query}\n",
        "\n",
        "    Instructions:\n",
        "    1. Answer based ONLY on the provided context\n",
        "    2. Mention which document type(s) contain the information\n",
        "    3. Be concise (< 500 characters) but complete\n",
        "    4. If the context doesn't contain enough information, say so\n",
        "\n",
        "    Answer:\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        answer = llm_generate(prompt).strip()\n",
        "\n",
        "\n",
        "        # Calculate overall confidence based on retrieval scores\n",
        "        avg_score = sum(s for _, s in retrieved_chunks) / len(retrieved_chunks)\n",
        "\n",
        "        return {\n",
        "            'answer': answer,\n",
        "            'sources': sources,\n",
        "            'confidence': avg_score,\n",
        "            'chunks_used': len(retrieved_chunks)\n",
        "        }\n",
        "    except Exception as e:\n",
        "        print(f\"Answer generation error: {e}\")\n",
        "        return {\n",
        "            'answer': f\"Error generating answer: {str(e)}\",\n",
        "            'sources': sources,\n",
        "            'confidence': 0.0\n",
        "        }"
      ],
      "metadata": {
        "id": "IITpvhTeLRsg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üèóÔ∏è Enhanced Document Store"
      ],
      "metadata": {
        "id": "VbvV4zsCLTEu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "class EnhancedDocumentStore:\n",
        "    \"\"\"\n",
        "    Manages the complete document processing and retrieval pipeline.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.pages_info = []\n",
        "        self.logical_docs = []\n",
        "        self.chunks_metadata = []\n",
        "        self.retriever = IntelligentRetriever()\n",
        "        self.is_ready = False\n",
        "        self.processing_stats = {}\n",
        "        self.filename = None\n",
        "\n",
        "    def process_pdf(self, pdf_file, filename: str = \"document.pdf\"):\n",
        "        \"\"\"\n",
        "        Complete PDF processing pipeline.\n",
        "        \"\"\"\n",
        "        self.filename = filename\n",
        "        self.is_ready = False\n",
        "        start_time = datetime.now()\n",
        "\n",
        "        try:\n",
        "            # Extract and analyze PDF\n",
        "            self.pages_info, self.logical_docs = extract_and_analyze_pdf(pdf_file)\n",
        "\n",
        "            # Chunk documents with metadata\n",
        "            self.chunks_metadata = process_all_documents(self.logical_docs)\n",
        "\n",
        "            # Build retrieval indices\n",
        "            self.retriever.build_indices(self.chunks_metadata)\n",
        "\n",
        "            # Calculate processing statistics\n",
        "            process_time = (datetime.now() - start_time).total_seconds()\n",
        "            self.processing_stats = {\n",
        "                'filename': filename,\n",
        "                'total_pages': len(self.pages_info),\n",
        "                'documents_found': len(self.logical_docs),\n",
        "                'total_chunks': len(self.chunks_metadata),\n",
        "                'document_types': list(set(doc.doc_type for doc in self.logical_docs)),\n",
        "                'processing_time': f\"{process_time:.1f}s\"\n",
        "            }\n",
        "\n",
        "            self.is_ready = True\n",
        "            return True, self.processing_stats\n",
        "\n",
        "        except Exception as e:\n",
        "            return False, {'error': str(e)}\n",
        "\n",
        "    def query(self, question: str, filter_type: Optional[str] = None,\n",
        "          auto_route: bool = True, k: int = 4) -> Dict:\n",
        "        \"\"\"\n",
        "        Query the document store.\n",
        "        \"\"\"\n",
        "        if not self.is_ready:\n",
        "            return {\n",
        "                'answer': \"Please upload and process a PDF first.\",\n",
        "                'sources': [],\n",
        "                'confidence': 0.0\n",
        "            }\n",
        "\n",
        "        t0 = time.time()  # ‚úÖ start timer\n",
        "\n",
        "        # Retrieve relevant chunks\n",
        "        retrieved = self.retriever.retrieve(\n",
        "            question, k=k,\n",
        "            filter_doc_type=filter_type,\n",
        "            auto_route=auto_route\n",
        "        )\n",
        "\n",
        "        # Generate answer with sources\n",
        "        result = generate_answer_with_sources(question, retrieved)\n",
        "        result['filter_used'] = filter_type or ('auto' if auto_route else 'none')\n",
        "\n",
        "        result['latency_sec'] = round(time.time() - t0, 2)  # ‚úÖ end timer\n",
        "        return result\n",
        "\n",
        "\n",
        "    def get_document_structure(self) -> List[Dict]:\n",
        "        \"\"\"\n",
        "        Get the document structure for UI display.\n",
        "        \"\"\"\n",
        "        if not self.logical_docs:\n",
        "            return []\n",
        "\n",
        "        structure = []\n",
        "        for doc in self.logical_docs:\n",
        "            structure.append({\n",
        "                'id': doc.doc_id,\n",
        "                'type': doc.doc_type,\n",
        "                'pages': f\"{doc.page_start + 1}-{doc.page_end + 1}\",  # 1-indexed for UI\n",
        "                'chunks': len(doc.chunks) if doc.chunks else 0,\n",
        "                'preview': doc.text[:200] + \"...\" if len(doc.text) > 200 else doc.text\n",
        "            })\n",
        "\n",
        "        return structure"
      ],
      "metadata": {
        "id": "lyy5OLSTLViM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üé® Demo UI (Gradio)\n",
        "Interactive interface to:\n",
        "- Upload and preview PDFs\n",
        "- Process + segment documents\n",
        "- Ask questions with optional filters\n",
        "- Download chat logs for evaluation evidence"
      ],
      "metadata": {
        "id": "sbeCC7ItLWpA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize global document store for the demo session\n",
        "doc_store = EnhancedDocumentStore()\n",
        "\n",
        "def process_pdf_handler(pdf_file):\n",
        "    \"\"\"Handle PDF upload and processing.\"\"\"\n",
        "    if pdf_file is None:\n",
        "        return \"‚ö†Ô∏è Please upload a PDF file\", \"\", gr.update(choices=[\"All\"], value=\"All\")\n",
        "\n",
        "    # ‚úÖ pdf_file is a filepath string because gr.File(type=\"filepath\")\n",
        "    filename = os.path.basename(pdf_file) if isinstance(pdf_file, str) else getattr(pdf_file, \"name\", \"document.pdf\")\n",
        "\n",
        "    # Process the PDF\n",
        "    success, stats = doc_store.process_pdf(pdf_file, filename=filename)\n",
        "\n",
        "    if success:\n",
        "        # Prepare status message\n",
        "        status_msg = f\"\"\"\n",
        "‚úÖ **Successfully Processed:**\n",
        "- üìÑ File: {stats.get('filename', filename)}\n",
        "- üìë Pages: {stats.get('total_pages', 0)}\n",
        "- üìö Documents Found: {stats.get('documents_found', 0)}\n",
        "- üß© Chunks Created: {stats.get('total_chunks', 0)}\n",
        "- üè∑Ô∏è Types: {', '.join(stats.get('document_types', []))}\n",
        "- ‚è±Ô∏è Time: {stats.get('processing_time', 'N/A')}\n",
        "\"\"\"\n",
        "\n",
        "        # Get document structure for display\n",
        "        structure = doc_store.get_document_structure()\n",
        "        structure_display = \"\\n\".join([\n",
        "            f\"‚Ä¢ **{doc['type']}** (Pages {doc['pages']}): {doc['chunks']} chunks\"\n",
        "            for doc in structure\n",
        "        ]) if structure else \"_No structure detected._\"\n",
        "\n",
        "        # Update filter choices\n",
        "        doc_types = [\"All\"] + stats.get(\"document_types\", [\"Other\"])\n",
        "        return status_msg, structure_display, gr.update(choices=doc_types, value=\"All\")\n",
        "\n",
        "    return f\"‚ùå Error: {stats.get('error', 'Unknown error')}\", \"\", gr.update(choices=[\"All\"], value=\"All\")\n",
        "\n",
        "def _pdf_page_count(pdf_path: str) -> int:\n",
        "    doc = fitz.open(pdf_path)\n",
        "    n = doc.page_count\n",
        "    doc.close()\n",
        "    return max(1, n)\n",
        "\n",
        "def render_page(pdf_path: str, page_num: int):\n",
        "    \"\"\"Return (image_array, page_label_text).\"\"\"\n",
        "    if not pdf_path:\n",
        "        return None, \"Page 0 / 0\"\n",
        "\n",
        "    total = _pdf_page_count(pdf_path)\n",
        "    page_num = int(page_num)\n",
        "    page_num = max(1, min(page_num, total))\n",
        "\n",
        "    doc = fitz.open(pdf_path)\n",
        "    page = doc.load_page(page_num - 1)\n",
        "    pix = page.get_pixmap(matrix=fitz.Matrix(2, 2))\n",
        "    doc.close()\n",
        "\n",
        "    # ‚úÖ Convert pixmap to numpy array Gradio can display\n",
        "    img = np.frombuffer(pix.samples, dtype=np.uint8).reshape(pix.height, pix.width, pix.n)\n",
        "\n",
        "    return img, f\"Page {page_num} / {total}\"\n",
        "\n",
        "def on_pdf_uploaded(pdf_path: str):\n",
        "    \"\"\"Hide uploader, show viewer, initialize page=1.\"\"\"\n",
        "    if not pdf_path:\n",
        "        return (\n",
        "            gr.update(visible=True),   # upload_box\n",
        "            gr.update(visible=False),  # viewer_box\n",
        "            None,                      # page_image\n",
        "            1,                         # page_state\n",
        "            \"Page 0 / 0\",              # page_label\n",
        "            None                       # stored_pdf\n",
        "        )\n",
        "\n",
        "    img, label = render_page(pdf_path, 1)\n",
        "    return (\n",
        "        gr.update(visible=False),     # upload_box\n",
        "        gr.update(visible=True),      # viewer_box\n",
        "        img,                          # page_image\n",
        "        1,                            # page_state\n",
        "        label,                        # page_label\n",
        "        pdf_path                      # stored_pdf\n",
        "    )\n",
        "\n",
        "def go_next(pdf_path: str, page_num: int):\n",
        "    if not pdf_path:\n",
        "        return None, page_num, \"Page 0 / 0\"\n",
        "    total = _pdf_page_count(pdf_path)\n",
        "    page_num = min(int(page_num) + 1, total)\n",
        "    img, label = render_page(pdf_path, page_num)\n",
        "    return img, page_num, label\n",
        "\n",
        "def go_prev(pdf_path: str, page_num: int):\n",
        "    if not pdf_path:\n",
        "        return None, page_num, \"Page 0 / 0\"\n",
        "    page_num = max(int(page_num) - 1, 1)\n",
        "    img, label = render_page(pdf_path, page_num)\n",
        "    return img, page_num, label\n",
        "\n",
        "def replace_pdf():\n",
        "    \"\"\"Show uploader again and hide viewer.\"\"\"\n",
        "    return (\n",
        "        gr.update(visible=True),   # upload_box\n",
        "        gr.update(visible=False),  # viewer_box\n",
        "        None,                      # page_image\n",
        "        1,                         # page_state\n",
        "        \"Page 0 / 0\",              # page_label\n",
        "        None                       # stored_pdf\n",
        "    )\n",
        "\n",
        "def chat_handler(message, history, doc_filter, auto_route, num_chunks):\n",
        "    # Gradio \"messages format\": list of dicts with role/content\n",
        "    history = history or []\n",
        "\n",
        "    if not doc_store.is_ready:\n",
        "        history.append({\"role\": \"user\", \"content\": message})\n",
        "        history.append({\"role\": \"assistant\", \"content\": \"üìö Please upload and process a PDF document first.\"})\n",
        "        return history\n",
        "\n",
        "    filter_type = None if doc_filter == \"All\" else doc_filter\n",
        "\n",
        "    result = doc_store.query(\n",
        "        message,\n",
        "        filter_type=filter_type,\n",
        "        auto_route=auto_route and filter_type is None,\n",
        "        k=int(num_chunks)\n",
        "    )\n",
        "\n",
        "    response = f\"{result.get('answer', '')}\\n\\n\"\n",
        "    if result.get(\"sources\"):\n",
        "        response += \"üìç **Sources:**\\n\"\n",
        "        for src in result[\"sources\"]:\n",
        "            response += f\"‚Ä¢ {src['doc_type']} (Pages {src['pages']}) - Relevance: {src['relevance']}\\n\"\n",
        "\n",
        "    response += (\n",
        "        f\"\\n*Confidence: {result.get('confidence', 0.0):.1%} | \"\n",
        "        f\"Filter: {result.get('filter_used', 'auto')} | \"\n",
        "        f\"Latency: {result.get('latency_sec', 'N/A')}s*\"\n",
        "    )\n",
        "\n",
        "    history.append({\"role\": \"user\", \"content\": message})\n",
        "    history.append({\"role\": \"assistant\", \"content\": response})\n",
        "\n",
        "    return history\n",
        "\n",
        "\n",
        "def _content_to_text(content):\n",
        "    \"\"\"Convert Gradio content (str | list | dict) into plain text.\"\"\"\n",
        "    if content is None:\n",
        "        return \"\"\n",
        "    if isinstance(content, str):\n",
        "        return content\n",
        "    if isinstance(content, list):\n",
        "        # Could be list of strings or list of dict parts\n",
        "        parts = []\n",
        "        for item in content:\n",
        "            if isinstance(item, str):\n",
        "                parts.append(item)\n",
        "            elif isinstance(item, dict):\n",
        "                # common shapes: {\"text\": \"...\"} or {\"type\":\"text\",\"text\":\"...\"}\n",
        "                parts.append(str(item.get(\"text\") or item.get(\"content\") or item))\n",
        "            else:\n",
        "                parts.append(str(item))\n",
        "        return \"\\n\".join([p for p in parts if p]).strip()\n",
        "    if isinstance(content, dict):\n",
        "        return str(content.get(\"text\") or content.get(\"content\") or content).strip()\n",
        "    return str(content).strip()\n",
        "\n",
        "def save_chat_txt(history):\n",
        "    \"\"\"Save chat to a .txt file and return filepath for download.\"\"\"\n",
        "    history = history or []\n",
        "\n",
        "    fd, path = tempfile.mkstemp(suffix=\".txt\", prefix=\"chat_\")\n",
        "    os.close(fd)\n",
        "\n",
        "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(\"Document Q&A Chat Log\\n\")\n",
        "        f.write(f\"Saved: {datetime.now().isoformat()}\\n\")\n",
        "        f.write(f\"PDF: {getattr(doc_store, 'filename', None)}\\n\")\n",
        "        f.write(\"\\n\" + \"=\" * 50 + \"\\n\\n\")\n",
        "\n",
        "        # CASE A: old Gradio tuple format [(user, bot), ...]\n",
        "        if len(history) > 0 and isinstance(history[0], (list, tuple)) and len(history[0]) == 2:\n",
        "            for i, (u, a) in enumerate(history, start=1):\n",
        "                f.write(f\"--- Turn {i} ---\\n\")\n",
        "                f.write(f\"USER: {_content_to_text(u)}\\n\\n\")\n",
        "                f.write(f\"ASSISTANT: {_content_to_text(a)}\\n\\n\")\n",
        "            return path\n",
        "\n",
        "        # CASE B: messages format [{\"role\": \"...\", \"content\": ...}, ...]\n",
        "        turn = 0\n",
        "        for msg in history:\n",
        "            if not isinstance(msg, dict):\n",
        "                # fallback if Gradio gives something unexpected\n",
        "                f.write(f\"{_content_to_text(msg)}\\n\\n\")\n",
        "                continue\n",
        "\n",
        "            role = str(msg.get(\"role\", \"unknown\")).upper()\n",
        "            content = _content_to_text(msg.get(\"content\"))\n",
        "            if not content:\n",
        "                continue\n",
        "\n",
        "            if role == \"USER\":\n",
        "                turn += 1\n",
        "                f.write(f\"--- Turn {turn} ---\\n\")\n",
        "\n",
        "            f.write(f\"{role}: {content}\\n\\n\")\n",
        "\n",
        "    return path\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def create_interface():\n",
        "    \"\"\"Create the enhanced Gradio interface with unified single-tab layout.\"\"\"\n",
        "    with gr.Blocks(title=\"Enhanced Document Q&A\", theme=gr.themes.Soft()) as demo:\n",
        "        gr.Markdown(\"\"\"\n",
        "# üöÄ Enhanced Document Q&A System\n",
        "### Intelligent Multi-Document Analysis with Advanced RAG Pipeline\n",
        "\"\"\")\n",
        "\n",
        "        with gr.Row():\n",
        "            # Left side - PDF preview and upload\n",
        "            with gr.Column(scale=2):\n",
        "\n",
        "                # --- NEW: two \"boxes\" in the SAME spot ---\n",
        "                upload_box = gr.Column(visible=True)\n",
        "                viewer_box = gr.Column(visible=False)\n",
        "\n",
        "                # --- NEW: state for current page + stored pdf path ---\n",
        "                page_state = gr.State(1)\n",
        "                stored_pdf = gr.State(None)\n",
        "\n",
        "                with upload_box:\n",
        "                    pdf_input = gr.File(\n",
        "                        label=\"üìÑ Upload PDF\",\n",
        "                        file_types=[\".pdf\"],\n",
        "                        type=\"filepath\"  # gives you a path string\n",
        "                    )\n",
        "\n",
        "                with viewer_box:\n",
        "                    page_label = gr.Markdown(\"Page 0 / 0\")\n",
        "                    page_image = gr.Image(label=\"PDF Page Preview\", height=600)\n",
        "\n",
        "                    with gr.Row():\n",
        "                        prev_btn = gr.Button(\"‚¨ÖÔ∏è Prev\", scale=1)\n",
        "                        next_btn = gr.Button(\"Next ‚û°Ô∏è\", scale=1)\n",
        "                        replace_btn = gr.Button(\"üîÅ Replace PDF\", scale=1)\n",
        "\n",
        "                with gr.Row():\n",
        "                    process_btn = gr.Button(\n",
        "                        \"üîÑ Process Document\",\n",
        "                        variant=\"primary\",\n",
        "                        size=\"lg\",\n",
        "                        scale=2\n",
        "                    )\n",
        "                    clear_all_btn = gr.Button(\n",
        "                        \"üóëÔ∏è Clear All\",\n",
        "                        variant=\"secondary\",\n",
        "                        size=\"lg\",\n",
        "                        scale=1\n",
        "                    )\n",
        "\n",
        "            # Middle - Document info and settings\n",
        "            with gr.Column(scale=1):\n",
        "                gr.Markdown(\"### üìä Document Info\")\n",
        "                status_output = gr.Markdown(\n",
        "                    value=\"‚è≥ Waiting for PDF upload...\"\n",
        "                )\n",
        "\n",
        "                structure_output = gr.Markdown(\n",
        "                    value=\"\",\n",
        "                    label=\"Document Structure\"\n",
        "                )\n",
        "\n",
        "                gr.Markdown(\"### ‚öôÔ∏è Settings\")\n",
        "                doc_filter = gr.Dropdown(\n",
        "                    choices=[\"All\"],\n",
        "                    value=\"All\",\n",
        "                    label=\"üè∑Ô∏è Document Type Filter\",\n",
        "                    info=\"Filter search to specific document type\"\n",
        "                )\n",
        "\n",
        "                auto_route = gr.Checkbox(\n",
        "                    value=True,\n",
        "                    label=\"üéØ Auto-Route Queries\",\n",
        "                    info=\"Automatically detect relevant document type\"\n",
        "                )\n",
        "\n",
        "                num_chunks = gr.Slider(\n",
        "                    minimum=1,\n",
        "                    maximum=10,\n",
        "                    value=4,\n",
        "                    step=1,\n",
        "                    label=\"üìä Chunks to Retrieve\"\n",
        "                )\n",
        "\n",
        "            # Right side - Chat interface\n",
        "            with gr.Column(scale=2):\n",
        "                gr.Markdown(\"### üí¨ Ask Questions\")\n",
        "                chatbot = gr.Chatbot(\n",
        "                  label=\"Conversation\",\n",
        "                  height=500,\n",
        "                  elem_id=\"chatbot\",\n",
        "                  show_label=False,\n",
        "                )\n",
        "\n",
        "                with gr.Row():\n",
        "                    msg_input = gr.Textbox(\n",
        "                        label=\"Ask a question\",\n",
        "                        placeholder=\"e.g., What are the payment terms? What is the total amount?\",\n",
        "                        scale=4,\n",
        "                        show_label=False\n",
        "                    )\n",
        "                    send_btn = gr.Button(\"üì§ Send\", scale=1, variant=\"primary\")\n",
        "\n",
        "                with gr.Row():\n",
        "                    example_btn1 = gr.Button(\"üìù What's the summary?\", size=\"sm\", scale=1)\n",
        "                    example_btn2 = gr.Button(\"üí∞ Find amounts\", size=\"sm\", scale=1)\n",
        "\n",
        "                with gr.Row():\n",
        "                    clear_chat_btn = gr.Button(\"üóëÔ∏è Clear Chat\", size=\"sm\", scale=1)\n",
        "\n",
        "\n",
        "                with gr.Row():\n",
        "                    download_chat_btn = gr.DownloadButton(\"üíæ Download Chat (.txt)\", variant= \"primary\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        # Status bar at the bottom\n",
        "        with gr.Row():\n",
        "            status_bar = gr.Markdown(\n",
        "                value=\"**Status:** Ready | **Documents:** 0 | **Chunks:** 0 | **Cache Hits:** 0/0\",\n",
        "                elem_id=\"status_bar\"\n",
        "            )\n",
        "\n",
        "        # Event handlers\n",
        "        def update_status_bar():\n",
        "            \"\"\"Update the status bar with current statistics.\"\"\"\n",
        "            if doc_store.is_ready:\n",
        "                stats = doc_store.processing_stats\n",
        "\n",
        "                # ‚úÖ Safe getattr so it never crashes\n",
        "                total_q = getattr(doc_store.retriever, \"total_queries\", 0)\n",
        "                hits = getattr(doc_store.retriever, \"cache_hits\", 0)\n",
        "                cache_rate = (hits / total_q) * 100 if total_q else 0\n",
        "\n",
        "                return (\n",
        "                    f\"**Status:** ‚úÖ Ready | **Documents:** {stats.get('documents_found', 0)} | \"\n",
        "                    f\"**Chunks:** {stats.get('total_chunks', 0)} | **Cache Rate:** {cache_rate:.0f}%\"\n",
        "                )\n",
        "            return \"**Status:** Ready | **Documents:** 0 | **Chunks:** 0 | **Cache Hits:** 0/0\"\n",
        "\n",
        "        def clear_all():\n",
        "            \"\"\"Clear everything and reset the interface.\"\"\"\n",
        "            global doc_store\n",
        "            doc_store = EnhancedDocumentStore()\n",
        "            return (\n",
        "                None,  # pdf_input\n",
        "                \"‚è≥ Waiting for PDF upload...\",  # status_output\n",
        "                \"\",  # structure_output\n",
        "                gr.update(choices=[\"All\"], value=\"All\"),  # doc_filter\n",
        "                [],  # chatbot\n",
        "                \"\",  # msg_input\n",
        "                update_status_bar(),  # status_bar\n",
        "                gr.update(visible=True),   # upload_box\n",
        "                gr.update(visible=False),  # viewer_box\n",
        "                None,  # page_image\n",
        "                \"Page 0 / 0\",  # page_label\n",
        "                1,  # page_state\n",
        "                None  # stored_pdf\n",
        "            )\n",
        "\n",
        "        # Process PDF handler with status bar update\n",
        "        def process_pdf_with_status(pdf_file):\n",
        "            status, structure, filter_update = process_pdf_handler(pdf_file)\n",
        "            status_bar_text = update_status_bar()\n",
        "            return status, structure, filter_update, status_bar_text\n",
        "\n",
        "        # Chat handler with status bar update\n",
        "        def chat_with_status(message, history, doc_filter, auto_route, num_chunks):\n",
        "            new_history = chat_handler(message, history, doc_filter, auto_route, num_chunks)\n",
        "            status_bar_text = update_status_bar()\n",
        "            return new_history, status_bar_text\n",
        "\n",
        "        # Example question handlers\n",
        "        def ask_summary(history, doc_filter, auto_route, num_chunks):\n",
        "            return chat_handler(\n",
        "                \"Can you provide a summary of the main points in this document?\",\n",
        "                history, doc_filter, auto_route, num_chunks\n",
        "            )\n",
        "\n",
        "        def ask_amounts(history, doc_filter, auto_route, num_chunks):\n",
        "            return chat_handler(\n",
        "                \"What are all the monetary amounts or financial figures mentioned?\",\n",
        "                history, doc_filter, auto_route, num_chunks\n",
        "            )\n",
        "\n",
        "        # Wire up all the events\n",
        "        process_btn.click(\n",
        "            fn=process_pdf_with_status,\n",
        "            inputs=[pdf_input],\n",
        "            outputs=[status_output, structure_output, doc_filter, status_bar]\n",
        "        )\n",
        "\n",
        "        clear_all_btn.click(\n",
        "            fn=clear_all,\n",
        "            outputs=[\n",
        "                pdf_input, status_output, structure_output, doc_filter,\n",
        "                chatbot, msg_input, status_bar,\n",
        "                upload_box, viewer_box, page_image, page_label, page_state, stored_pdf\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        # Chat interactions\n",
        "        msg_input.submit(\n",
        "            fn=chat_with_status,\n",
        "            inputs=[msg_input, chatbot, doc_filter, auto_route, num_chunks],\n",
        "            outputs=[chatbot, status_bar]\n",
        "        ).then(lambda: \"\", outputs=[msg_input])\n",
        "\n",
        "        send_btn.click(\n",
        "            fn=chat_with_status,\n",
        "            inputs=[msg_input, chatbot, doc_filter, auto_route, num_chunks],\n",
        "            outputs=[chatbot, status_bar]\n",
        "        ).then(lambda: \"\", outputs=[msg_input])\n",
        "\n",
        "        clear_chat_btn.click(lambda: [], outputs=[chatbot])\n",
        "\n",
        "        example_btn1.click(\n",
        "            fn=ask_summary,\n",
        "            inputs=[chatbot, doc_filter, auto_route, num_chunks],\n",
        "            outputs=[chatbot]\n",
        "        ).then(fn=update_status_bar, outputs=[status_bar])\n",
        "\n",
        "        example_btn2.click(\n",
        "            fn=ask_amounts,\n",
        "            inputs=[chatbot, doc_filter, auto_route, num_chunks],\n",
        "            outputs=[chatbot]\n",
        "        ).then(fn=update_status_bar, outputs=[status_bar])\n",
        "\n",
        "                # Auto-process when PDF is uploaded (your existing logic)\n",
        "        pdf_input.upload(\n",
        "            fn=process_pdf_with_status,\n",
        "            inputs=[pdf_input],\n",
        "            outputs=[status_output, structure_output, doc_filter, status_bar]\n",
        "        )\n",
        "\n",
        "        pdf_input.upload(\n",
        "            fn=on_pdf_uploaded,\n",
        "            inputs=[pdf_input],\n",
        "            outputs=[upload_box, viewer_box, page_image, page_state, page_label, stored_pdf]\n",
        "        )\n",
        "\n",
        "        # ‚úÖ BULLETPROOF: Colab sometimes doesn't fire .upload(), so also use .change()\n",
        "        pdf_input.change(\n",
        "            fn=process_pdf_with_status,\n",
        "            inputs=[pdf_input],\n",
        "            outputs=[status_output, structure_output, doc_filter, status_bar]\n",
        "        )\n",
        "\n",
        "        pdf_input.change(\n",
        "            fn=on_pdf_uploaded,\n",
        "            inputs=[pdf_input],\n",
        "            outputs=[upload_box, viewer_box, page_image, page_state, page_label, stored_pdf]\n",
        "        )\n",
        "\n",
        "        # ‚úÖ page navigation buttons (fix output order)\n",
        "        prev_btn.click(\n",
        "            fn=go_prev,\n",
        "            inputs=[stored_pdf, page_state],\n",
        "            outputs=[page_image, page_state, page_label]\n",
        "        )\n",
        "\n",
        "        next_btn.click(\n",
        "            fn=go_next,\n",
        "            inputs=[stored_pdf, page_state],\n",
        "            outputs=[page_image, page_state, page_label]\n",
        "        )\n",
        "\n",
        "        # ‚úÖ replace button (fix output order)\n",
        "        replace_btn.click(\n",
        "            fn=replace_pdf,\n",
        "            outputs=[upload_box, viewer_box, page_image, page_state, page_label, stored_pdf]\n",
        "        )\n",
        "\n",
        "        # DownloadButton expects a filepath.\n",
        "        #We generate a .txt file from chat history and return its path.\n",
        "        download_chat_btn.click(\n",
        "            fn=save_chat_txt,\n",
        "            inputs=[chatbot],\n",
        "            outputs=[download_chat_btn]\n",
        "        )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    return demo\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "k7wXGcnJN6rf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(llm_generate(\"Respond with ONLY this exact word: Resume\"))\n"
      ],
      "metadata": {
        "id": "bJy3LUn-6Wqo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "demo = create_interface()\n",
        "demo.launch(share=True, debug=True)"
      ],
      "metadata": {
        "id": "LJJxZwTpN_pQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}